"""
High-level extraction from pre-processed annual mean NetCDF files.

Main entry point for extracting carbon cycle variables from annual mean files
generated by CDO or similar tools.
"""

import os
import glob
import warnings
import numpy as np

# Configure Iris and suppress warnings before importing
try:
    import iris
    iris.FUTURE.date_microseconds = True
except AttributeError:
    import iris

# Suppress Iris warnings
warnings.filterwarnings('ignore', message='.*date precision.*', category=FutureWarning)
warnings.filterwarnings('ignore', message='.*DEFAULT_SPHERICAL_EARTH_RADIUS.*')

from iris import Constraint

from ..io import stash, try_extract
from ..processing.regional import load_reccap_mask, compute_regional_annual_mean
from ..config import (
    DEFAULT_VAR_LIST,
    resolve_variable_name,
    get_variable_config,
    get_conversion_key,
)


def extract_annual_means(expts_list, var_list=None, var_mapping=None, regions=None, base_dir='~/annual_mean'):
    """
    Extract annual means from pre-processed NetCDF files.

    Main workhorse function for extracting carbon cycle variables from
    pre-processed annual mean files.

    Parameters
    ----------
    expts_list : list of str
        List of experiment names (e.g., ['xqhuc', 'xqhsh'])
    var_list : list of str, optional
        Variable names to extract (CMIP-style canonical names preferred).
        Default: ['Rh', 'CSoil', 'CVeg', 'frac', 'GPP', 'NPP', 'fgco2', 'tas', 'pr', 'co2']

        Aliases supported but deprecated (will be removed in v0.3.0):
        - Use 'Rh' not 'soilResp'
        - Use 'CVeg' not 'VegCarb'
        - Use 'CSoil' not 'soilCarbon'
        - Use 'tas' not 'temp'
        - Use 'pr' not 'precip'
        - Use 'co2' not 'Total co2'
    var_mapping : list of str, optional
        **DEPRECATED**. This parameter is no longer needed.
        Conversion keys are now looked up automatically from the canonical
        variable registry in config.py. Will be removed in v0.3.0.
    regions : list of str, optional
        Region names to process. Default: all RECCAP2 regions + 'Africa' + 'global'
    base_dir : str, optional
        Base directory containing experiment subdirectories with annual mean files.
        Default: '~/annual_mean'

        Each experiment should have a subdirectory: {base_dir}/{expt}/

    Returns
    -------
    dict
        Nested dictionary with structure:
        {expt: {region: {var: {'years': array, 'data': array, 'units': str,
                                'name': str, 'region': str}}}}

    Examples
    --------
    >>> # Extract for single experiment, all regions (using canonical names)
    >>> ds = extract_annual_means(['xqhuc'])
    >>> ds['xqhuc']['global']['GPP']['data']  # Global GPP time series
    >>> ds['xqhuc']['global']['Rh']['data']   # Heterotrophic respiration

    >>> # Extract for multiple experiments, specific regions
    >>> ds = extract_annual_means(['xqhuc', 'xqhsh'],
    ...                          regions=['global', 'Europe', 'Africa'])
    >>> ds['xqhuc']['Europe']['NPP']['data']  # Europe NPP for xqhuc

    >>> # With custom base directory
    >>> ds = extract_annual_means(['xqhuc'], base_dir='~/data/annual_mean')

    >>> # Backward compatible: aliases still work (with deprecation warning)
    >>> ds = extract_annual_means(['xqhuc'], var_list=['VegCarb', 'soilResp'])
    >>> # DeprecationWarning: Use 'CVeg' not 'VegCarb', 'Rh' not 'soilResp'

    Notes
    -----
    Input files expected in: {base_dir}/{expt}/
    - {expt}_pt_annual_mean.nc (TRIFFID: GPP, NPP, soil resp, carbon, PFTs)
    - {expt}_pd_annual_mean.nc (atmosphere: temp, precip)
    - {expt}_pf_annual_mean.nc (ocean: fgco2)

    Derived variables computed automatically:
    - NEP = NPP - Rh
    - Land Carbon = CSoil + CVeg + NEP
    - Trees Total = PFT1 + PFT2

    Detailed diagnostic output printed to stdout showing:
    - Files found
    - Variables successfully extracted (✓) or missing (❌)
    - Summary of extraction status

    See Also
    --------
    config.CANONICAL_VARIABLES : Variable registry with all metadata
    config.resolve_variable_name : Resolve aliases to canonical names
    """
    # Handle deprecated var_mapping parameter
    if var_mapping is not None:
        warnings.warn(
            "The 'var_mapping' parameter is deprecated and will be removed in v0.3.0. "
            "Conversion keys are now automatically looked up from the canonical variable registry.",
            DeprecationWarning,
            stacklevel=2
        )

    # Use default variable list if not provided
    if var_list is None:
        var_list = DEFAULT_VAR_LIST

    # Resolve variable names to canonical names (with deprecation warnings for aliases)
    resolved_vars = []
    for var in var_list:
        try:
            canonical = resolve_variable_name(var)
            if var != canonical:
                warnings.warn(
                    f"Variable name '{var}' is deprecated. "
                    f"Use canonical name '{canonical}' instead. "
                    f"Aliases will be removed in v0.3.0.",
                    DeprecationWarning,
                    stacklevel=2
                )
            resolved_vars.append(canonical)
        except ValueError as e:
            warnings.warn(f"Skipping unknown variable '{var}': {e}", UserWarning, stacklevel=2)

    var_list = resolved_vars

    dict_annual_means = {}
    dict_frac = {}
    dict_temp = {}
    dict_precip = {}

    _, regions_dict = load_reccap_mask()
    all_regions = list(regions_dict.values()) + ['Africa', 'global']
    target_regions = regions if regions is not None else all_regions

    for expt in expts_list:
        expt_dir = os.path.join(base_dir, expt)
        dict_annual_means[expt] = {}
        expt_dir = os.path.expanduser(expt_dir)
        os.makedirs(expt_dir, exist_ok=True)

        filenames = glob.glob(os.path.join(expt_dir, "**/*.nc"), recursive=True)

        # Report files found
        print(f"\n{'='*60}")
        print(f"Extracting data for experiment: {expt}")
        print(f"{'='*60}")
        print(f"Looking in: {expt_dir}")
        print(f"NetCDF files found: {len(filenames)}")
        if filenames:
            for f in filenames:
                print(f"  - {os.path.basename(f)}")
        else:
            print(f"  ⚠ WARNING: No NetCDF files found!")
            print(f"  Expected files like: {expt}_pt_annual_mean.nc, {expt}_pd_annual_mean.nc, {expt}_pf_annual_mean.nc")

        cubes = iris.load(filenames)
        print(f"\nTotal cubes loaded: {len(cubes)}")

        # Extract variables using canonical registry
        print(f"\nExtracting variables...")

        # Build cube map using canonical names
        cube_map = {}

        for var_name in var_list:
            try:
                var_config = get_variable_config(var_name)
                stash_name = var_config['stash_name']
                stash_code = var_config['stash_code']
                stash_fallback = var_config.get('stash_fallback')

                # Try primary extraction
                extracted = try_extract(cubes, stash_name, stash_lookup_func=stash)

                if not extracted and stash_fallback:
                    # Try fallback (e.g., frac → fracb)
                    print(f"  ⚠ {var_name} ({stash_name}, {stash_code}): NOT FOUND, trying fallback {stash_fallback}")
                    extracted = try_extract(cubes, stash_fallback)
                    if not extracted:
                        print(f"  ❌ {var_name}: STILL NOT FOUND")
                    else:
                        print(f"  ✓ {var_name}: Found (via fallback {stash_fallback})")
                elif not extracted:
                    print(f"  ❌ {var_name} ({stash_name}, {stash_code}): NOT FOUND")
                else:
                    print(f"  ✓ {var_name} ({stash_name}): Found")

                cube_map[var_name] = extracted

            except Exception as e:
                # Don't let one variable failure stop the entire extraction
                print(f"  ❌ {var_name}: ERROR during extraction: {e}")
                import traceback
                traceback.print_exc()
                cube_map[var_name] = None

        # Store specific variables for backward compatibility
        dict_frac[expt] = cube_map.get('frac')
        dict_temp[expt] = cube_map.get('tas')
        dict_precip[expt] = cube_map.get('pr')

        # Summary of extraction status
        missing_vars = []
        found_vars = []
        for varname in var_list:
            cubeset = cube_map.get(varname)
            if not cubeset:
                missing_vars.append(varname)
            else:
                found_vars.append(varname)

        print(f"\n{'='*60}")
        print(f"Extraction Summary for {expt}")
        print(f"{'='*60}")
        print(f"Variables successfully extracted: {len(found_vars)}/{len(var_list)}")
        if found_vars:
            print(f"  Found: {', '.join(found_vars)}")
        if missing_vars:
            print(f"  ⚠ Missing: {', '.join(missing_vars)}")
            print(f"\n  These variables will NOT appear in plots!")
        print(f"{'='*60}\n")

        for region in target_regions:
            dict_annual_means[expt][region] = {}

            # Process each variable using canonical names and automatic conversion keys
            for varname in var_list:
                try:
                    cubeset = cube_map.get(varname)
                    if not cubeset:
                        continue  # Already warned above
                    if varname == 'fgco2' and region != 'global':
                        continue  # Skip fgco2 for non-global regions

                    cube = cubeset[0]
                    var_config = get_variable_config(varname)
                    conversion_key = get_conversion_key(varname)

                    # Handle regular variables
                    if cube is not None and varname != 'frac':
                        output = compute_regional_annual_mean(cube, conversion_key, region)
                        output['units'] = var_config['units']
                        dict_annual_means[expt][region][varname] = output
                    # Handle frac (PFTs) separately
                    elif cube is not None and varname == 'frac':
                        frac_data = {}

                        # Load IGBP obs for spatial RMSE (only for global region)
                        igbp_ds = None
                        if region == 'global':
                            try:
                                from ..validation.veg_fractions import (
                                    load_igbp_spatial, compute_spatial_rmse, PFT_MAPPING
                                )
                                igbp_ds = load_igbp_spatial()
                            except (ImportError, Exception):
                                pass

                        for j in range(1, 10):
                            try:
                                frac_pft = cube.extract(Constraint(coord_values={'generic': j}))
                                if frac_pft:
                                    output = compute_regional_annual_mean(frac_pft, conversion_key, region)

                                    # Compute spatial RMSE against IGBP obs (global only)
                                    if region == 'global' and igbp_ds is not None:
                                        pft_name = PFT_MAPPING.get(j)
                                        spatial_var = f'{pft_name}_2D' if pft_name else None
                                        if spatial_var and spatial_var in igbp_ds:
                                            try:
                                                # Time-mean of model field (preserve lat/lon)
                                                model_field = frac_pft.collapsed('time', iris.analysis.MEAN).data
                                                obs_field = igbp_ds[spatial_var].squeeze().values
                                                output['rmse'] = compute_spatial_rmse(model_field, obs_field)
                                            except Exception:
                                                pass

                                    frac_data[f'PFT {j}'] = output
                            except Exception as e:
                                # Skip PFTs that fail extraction
                                continue

                        # Close IGBP dataset if opened
                        if igbp_ds is not None:
                            igbp_ds.close()

                        # Only add frac data if at least one PFT was successfully extracted
                        if frac_data:
                            dict_annual_means[expt][region][varname] = frac_data

                except Exception as e:
                    # Don't let regional processing errors stop the entire extraction
                    print(f"  ⚠ Warning: Failed to process {varname} for region {region}: {e}")
                    continue

            # NEP (derived variable: NPP - Rh)
            if 'NPP' in dict_annual_means[expt][region] and 'Rh' in dict_annual_means[expt][region]:
                nep_years = dict_annual_means[expt][region]['NPP']['years'].copy()
                nep_data = dict_annual_means[expt][region]['NPP']['data'] - dict_annual_means[expt][region]['Rh']['data']
                dict_annual_means[expt][region]['NEP'] = {
                    'years': nep_years,
                    'data': nep_data,
                    'name': 'Net Ecosystem Production',
                    'units': dict_annual_means[expt][region]['NPP']['units'],
                    'region': region
                }

            # Land Carbon (derived variable: CSoil + CVeg + NEP)
            if all(k in dict_annual_means[expt][region] for k in ['CSoil', 'CVeg', 'NEP']):
                lc_years = dict_annual_means[expt][region]['NEP']['years'].copy()
                lc_data = dict_annual_means[expt][region]['CSoil']['data'] + \
                          dict_annual_means[expt][region]['CVeg']['data'] + \
                          dict_annual_means[expt][region]['NEP']['data']
                dict_annual_means[expt][region]['Land Carbon'] = {
                    'years': lc_years,
                    'data': lc_data,
                    'name': 'Total Land Carbon',
                    'units': dict_annual_means[expt][region]['NPP']['units'],
                    'region': region
                }

            # Trees Total (PFT1 + PFT2)
            if 'frac' in dict_annual_means[expt][region] and \
               all(p in dict_annual_means[expt][region]['frac'] for p in ['PFT 1', 'PFT 2']):
                tree_years = dict_annual_means[expt][region]['frac']['PFT 1']['years'].copy()
                tree_data = dict_annual_means[expt][region]['frac']['PFT 1']['data'] + \
                            dict_annual_means[expt][region]['frac']['PFT 2']['data']
                dict_annual_means[expt][region]['Trees Total'] = {
                    'years': tree_years,
                    'data': tree_data,
                    'name': 'Total Trees Fraction',
                    'units': 'fraction',
                    'region': region
                }

    return dict_annual_means
