"""
High-level extraction from pre-processed annual mean NetCDF files.

Main entry point for extracting carbon cycle variables from annual mean files
generated by CDO or similar tools.
"""

import os
import glob
import warnings
import numpy as np
import iris
from iris import Constraint

from ..io import stash, try_extract
from ..processing.regional import load_reccap_mask, compute_regional_annual_mean
from ..config import (
    DEFAULT_VAR_LIST,
    resolve_variable_name,
    get_variable_config,
    get_conversion_key,
)


def extract_annual_means(expts_list, var_list=None, var_mapping=None, regions=None):
    """
    Extract annual means from pre-processed NetCDF files.

    Main workhorse function for extracting carbon cycle variables from
    pre-processed annual mean files located in ~/annual_mean/{expt}/.

    Parameters
    ----------
    expts_list : list of str
        List of experiment names (e.g., ['xqhuc', 'xqhsh'])
    var_list : list of str, optional
        Variable names to extract (CMIP-style canonical names preferred).
        Default: ['Rh', 'CSoil', 'CVeg', 'frac', 'GPP', 'NPP', 'fgco2', 'tas', 'pr']

        Aliases supported but deprecated (will be removed in v0.3.0):
        - Use 'Rh' not 'soilResp'
        - Use 'CVeg' not 'VegCarb'
        - Use 'CSoil' not 'soilCarbon'
        - Use 'tas' not 'temp'
        - Use 'pr' not 'precip'
    var_mapping : list of str, optional
        **DEPRECATED**. This parameter is no longer needed.
        Conversion keys are now looked up automatically from the canonical
        variable registry in config.py. Will be removed in v0.3.0.
    regions : list of str, optional
        Region names to process. Default: all RECCAP2 regions + 'Africa' + 'global'

    Returns
    -------
    dict
        Nested dictionary with structure:
        {expt: {region: {var: {'years': array, 'data': array, 'units': str,
                                'name': str, 'region': str}}}}

    Examples
    --------
    >>> # Extract for single experiment, all regions (using canonical names)
    >>> ds = extract_annual_means(['xqhuc'])
    >>> ds['xqhuc']['global']['GPP']['data']  # Global GPP time series
    >>> ds['xqhuc']['global']['Rh']['data']   # Heterotrophic respiration

    >>> # Extract for multiple experiments, specific regions
    >>> ds = extract_annual_means(['xqhuc', 'xqhsh'],
    ...                          regions=['global', 'Europe', 'Africa'])
    >>> ds['xqhuc']['Europe']['NPP']['data']  # Europe NPP for xqhuc

    >>> # Backward compatible: aliases still work (with deprecation warning)
    >>> ds = extract_annual_means(['xqhuc'], var_list=['VegCarb', 'soilResp'])
    >>> # DeprecationWarning: Use 'CVeg' not 'VegCarb', 'Rh' not 'soilResp'

    Notes
    -----
    Input files expected in: ~/annual_mean/{expt}/
    - {expt}_pt_annual_mean.nc (TRIFFID: GPP, NPP, soil resp, carbon, PFTs)
    - {expt}_pd_annual_mean.nc (atmosphere: temp, precip)
    - {expt}_pf_annual_mean.nc (ocean: fgco2)

    Derived variables computed automatically:
    - NEP = NPP - Rh
    - Land Carbon = CSoil + CVeg + NEP
    - Trees Total = PFT1 + PFT2

    Detailed diagnostic output printed to stdout showing:
    - Files found
    - Variables successfully extracted (✓) or missing (❌)
    - Summary of extraction status

    See Also
    --------
    config.CANONICAL_VARIABLES : Variable registry with all metadata
    config.resolve_variable_name : Resolve aliases to canonical names
    """
    # Handle deprecated var_mapping parameter
    if var_mapping is not None:
        warnings.warn(
            "The 'var_mapping' parameter is deprecated and will be removed in v0.3.0. "
            "Conversion keys are now automatically looked up from the canonical variable registry.",
            DeprecationWarning,
            stacklevel=2
        )

    # Use default variable list if not provided
    if var_list is None:
        var_list = DEFAULT_VAR_LIST

    # Resolve variable names to canonical names (with deprecation warnings for aliases)
    resolved_vars = []
    for var in var_list:
        try:
            canonical = resolve_variable_name(var)
            if var != canonical:
                warnings.warn(
                    f"Variable name '{var}' is deprecated. "
                    f"Use canonical name '{canonical}' instead. "
                    f"Aliases will be removed in v0.3.0.",
                    DeprecationWarning,
                    stacklevel=2
                )
            resolved_vars.append(canonical)
        except ValueError as e:
            warnings.warn(f"Skipping unknown variable '{var}': {e}", UserWarning, stacklevel=2)

    var_list = resolved_vars

    dict_annual_means = {}
    dict_frac = {}
    dict_temp = {}
    dict_precip = {}

    _, regions_dict = load_reccap_mask()
    all_regions = list(regions_dict.values()) + ['Africa', 'global']
    target_regions = regions if regions is not None else all_regions

    for expt in expts_list:
        base_dir = f'~/annual_mean/{expt}/'
        dict_annual_means[expt] = {}
        base_dir = os.path.expanduser(base_dir)
        os.makedirs(base_dir, exist_ok=True)

        filenames = glob.glob(os.path.join(base_dir, "**/*.nc"), recursive=True)

        # Report files found
        print(f"\n{'='*60}")
        print(f"Extracting data for experiment: {expt}")
        print(f"{'='*60}")
        print(f"Looking in: {base_dir}")
        print(f"NetCDF files found: {len(filenames)}")
        if filenames:
            for f in filenames:
                print(f"  - {os.path.basename(f)}")
        else:
            print(f"  ⚠ WARNING: No NetCDF files found!")
            print(f"  Expected files like: {expt}_pt_annual_mean.nc, {expt}_pd_annual_mean.nc, {expt}_pf_annual_mean.nc")

        cubes = iris.load(filenames)
        print(f"\nTotal cubes loaded: {len(cubes)}")

        # Extract variables using canonical registry
        print(f"\nExtracting variables...")

        # Build cube map using canonical names
        cube_map = {}

        for var_name in var_list:
            var_config = get_variable_config(var_name)
            stash_name = var_config['stash_name']
            stash_code = var_config['stash_code']
            stash_fallback = var_config.get('stash_fallback')

            # Try primary extraction
            extracted = try_extract(cubes, stash_name, stash_lookup_func=stash)

            if not extracted and stash_fallback:
                # Try fallback (e.g., frac → fracb)
                print(f"  ⚠ {var_name} ({stash_name}, {stash_code}): NOT FOUND, trying fallback {stash_fallback}")
                extracted = try_extract(cubes, stash_fallback)
                if not extracted:
                    print(f"  ❌ {var_name}: STILL NOT FOUND")
                else:
                    print(f"  ✓ {var_name}: Found (via fallback {stash_fallback})")
            elif not extracted:
                print(f"  ❌ {var_name} ({stash_name}, {stash_code}): NOT FOUND")
            else:
                print(f"  ✓ {var_name} ({stash_name}): Found")

            cube_map[var_name] = extracted

        # Store specific variables for backward compatibility
        dict_frac[expt] = cube_map.get('frac')
        dict_temp[expt] = cube_map.get('tas')
        dict_precip[expt] = cube_map.get('pr')

        # Summary of extraction status
        missing_vars = []
        found_vars = []
        for varname in var_list:
            cubeset = cube_map.get(varname)
            if not cubeset:
                missing_vars.append(varname)
            else:
                found_vars.append(varname)

        print(f"\n{'='*60}")
        print(f"Extraction Summary for {expt}")
        print(f"{'='*60}")
        print(f"Variables successfully extracted: {len(found_vars)}/{len(var_list)}")
        if found_vars:
            print(f"  Found: {', '.join(found_vars)}")
        if missing_vars:
            print(f"  ⚠ Missing: {', '.join(missing_vars)}")
            print(f"\n  These variables will NOT appear in plots!")
        print(f"{'='*60}\n")

        for region in target_regions:
            dict_annual_means[expt][region] = {}

            # Process each variable using canonical names and automatic conversion keys
            for varname in var_list:
                cubeset = cube_map.get(varname)
                if not cubeset:
                    continue  # Already warned above
                if varname == 'fgco2' and region != 'global':
                    continue  # Skip fgco2 for non-global regions

                cube = cubeset[0]
                var_config = get_variable_config(varname)
                conversion_key = get_conversion_key(varname)

                # Handle regular variables
                if cube is not None and varname != 'frac':
                    output = compute_regional_annual_mean(cube, conversion_key, region)
                    output['units'] = var_config['units']
                    dict_annual_means[expt][region][varname] = output
                # Handle frac (PFTs) separately
                else:
                    frac_data = {}
                    for j in range(1, 10):
                        try:
                            frac_pft = cube.extract(Constraint(coord_values={'generic': j}))
                            output = compute_regional_annual_mean(frac_pft, conversion_key, region)
                            frac_data[f'PFT {j}'] = output
                        except:
                            continue
                    dict_annual_means[expt][region][varname] = frac_data

            # NEP (derived variable: NPP - Rh)
            if 'NPP' in dict_annual_means[expt][region] and 'Rh' in dict_annual_means[expt][region]:
                nep_years = dict_annual_means[expt][region]['NPP']['years'].copy()
                nep_data = dict_annual_means[expt][region]['NPP']['data'] - dict_annual_means[expt][region]['Rh']['data']
                dict_annual_means[expt][region]['NEP'] = {
                    'years': nep_years,
                    'data': nep_data,
                    'name': 'Net Ecosystem Production',
                    'units': dict_annual_means[expt][region]['NPP']['units'],
                    'region': region
                }

            # Land Carbon (derived variable: CSoil + CVeg + NEP)
            if all(k in dict_annual_means[expt][region] for k in ['CSoil', 'CVeg', 'NEP']):
                lc_years = dict_annual_means[expt][region]['NEP']['years'].copy()
                lc_data = dict_annual_means[expt][region]['CSoil']['data'] + \
                          dict_annual_means[expt][region]['CVeg']['data'] + \
                          dict_annual_means[expt][region]['NEP']['data']
                dict_annual_means[expt][region]['Land Carbon'] = {
                    'years': lc_years,
                    'data': lc_data,
                    'name': 'Total Land Carbon',
                    'units': dict_annual_means[expt][region]['NPP']['units'],
                    'region': region
                }

            # Trees Total (PFT1 + PFT2)
            if 'frac' in dict_annual_means[expt][region] and \
               all(p in dict_annual_means[expt][region]['frac'] for p in ['PFT 1', 'PFT 2']):
                tree_years = dict_annual_means[expt][region]['frac']['PFT 1']['years'].copy()
                tree_data = dict_annual_means[expt][region]['frac']['PFT 1']['data'] + \
                            dict_annual_means[expt][region]['frac']['PFT 2']['data']
                dict_annual_means[expt][region]['Trees Total'] = {
                    'years': tree_years,
                    'data': tree_data,
                    'name': 'Total Trees Fraction',
                    'units': 'fraction',
                    'region': region
                }

    return dict_annual_means
