"""
High-level extraction from pre-processed annual mean NetCDF files.

Main entry point for extracting carbon cycle variables from annual mean files
generated by CDO or similar tools.
"""

import os
import glob
import numpy as np
import iris
from iris import Constraint

from ..io import stash, try_extract
from ..processing.regional import load_reccap_mask, compute_regional_annual_mean


def extract_annual_means(expts_list, var_list=None, var_mapping=None, regions=None):
    """
    Extract annual means from pre-processed NetCDF files.

    Main workhorse function for extracting carbon cycle variables from
    pre-processed annual mean files located in ~/annual_mean/{expt}/.

    Parameters
    ----------
    expts_list : list of str
        List of experiment names (e.g., ['xqhuc', 'xqhsh'])
    var_list : list of str, optional
        Variable names to extract. Default:
        ['soilResp', 'soilCarbon', 'VegCarb', 'fracPFTs', 'GPP', 'NPP',
         'fgco2', 'temp', 'precip']
    var_mapping : list of str, optional
        Mapping names for unit conversion. Must match var_list length.
        Default: ['S resp', 'S carb', 'V carb', 'Others', 'GPP', 'NPP',
                  'field646_mm_dpth', 'Others', 'precip']
    regions : list of str, optional
        Region names to process. Default: all RECCAP2 regions + 'Africa' + 'global'

    Returns
    -------
    dict
        Nested dictionary with structure:
        {expt: {region: {var: {'years': array, 'data': array, 'units': str,
                                'name': str, 'region': str}}}}

    Examples
    --------
    >>> # Extract for single experiment, all regions
    >>> ds = extract_annual_means(['xqhuc'])
    >>> ds['xqhuc']['global']['GPP']['data']  # Global GPP time series

    >>> # Extract for multiple experiments, specific regions
    >>> ds = extract_annual_means(['xqhuc', 'xqhsh'],
    ...                          regions=['global', 'Europe', 'Africa'])
    >>> ds['xqhuc']['Europe']['NPP']['data']  # Europe NPP for xqhuc

    Notes
    -----
    Input files expected in: ~/annual_mean/{expt}/
    - {expt}_pt_annual_mean.nc (TRIFFID: GPP, NPP, soil resp, carbon, PFTs)
    - {expt}_pd_annual_mean.nc (atmosphere: temp, precip)
    - {expt}_pf_annual_mean.nc (ocean: fgco2)

    Derived variables computed automatically:
    - NEP = NPP - soilResp
    - Land Carbon = soilCarbon + VegCarb + NEP
    - Trees Total = PFT1 + PFT2

    Detailed diagnostic output printed to stdout showing:
    - Files found
    - Variables successfully extracted (✓) or missing (❌)
    - Summary of extraction status
    """
    default_var_list = ['soilResp', 'soilCarbon', 'VegCarb', 'fracPFTs', 'GPP', 'NPP', 'fgco2', 'temp', 'precip']
    default_var_mapping = ['S resp', 'S carb', 'V carb', 'Others',
                          'GPP', 'NPP', 'field646_mm_dpth', 'Others', 'precip']
    if var_list is None:
        var_list = default_var_list

    # Generate default or custom var_mapping
    if var_mapping is None:
        var_mapping = default_var_mapping

    dict_annual_means = {}
    dict_frac = {}
    dict_temp = {}
    dict_precip = {}

    _, regions_dict = load_reccap_mask()
    all_regions = list(regions_dict.values()) + ['Africa', 'global']
    target_regions = regions if regions is not None else all_regions

    for expt in expts_list:
        base_dir = f'~/annual_mean/{expt}/'
        dict_annual_means[expt] = {}
        base_dir = os.path.expanduser(base_dir)
        os.makedirs(base_dir, exist_ok=True)

        filenames = glob.glob(os.path.join(base_dir, "**/*.nc"), recursive=True)

        # Report files found
        print(f"\n{'='*60}")
        print(f"Extracting data for experiment: {expt}")
        print(f"{'='*60}")
        print(f"Looking in: {base_dir}")
        print(f"NetCDF files found: {len(filenames)}")
        if filenames:
            for f in filenames:
                print(f"  - {os.path.basename(f)}")
        else:
            print(f"  ⚠ WARNING: No NetCDF files found!")
            print(f"  Expected files like: {expt}_pt_annual_mean.nc, {expt}_pd_annual_mean.nc, {expt}_pf_annual_mean.nc")

        cubes = iris.load(filenames)
        print(f"\nTotal cubes loaded: {len(cubes)}")

        # Extract variables with warnings
        print(f"\nExtracting variables...")

        sr = try_extract(cubes, 'rh', stash_lookup_func=stash)
        if not sr:
            print("  ❌ soilResp (rh, m01s03i293): NOT FOUND")
        else:
            print("  ✓ soilResp (rh): Found")

        sc = try_extract(cubes, 'cs', stash_lookup_func=stash)
        if not sc:
            print("  ❌ soilCarbon (cs, m01s19i016): NOT FOUND")
        else:
            print("  ✓ soilCarbon (cs): Found")

        vc = try_extract(cubes, 'cv', stash_lookup_func=stash)
        if not vc:
            print("  ❌ VegCarb (cv, m01s19i002): NOT FOUND")
        else:
            print("  ✓ VegCarb (cv): Found")

        frac = try_extract(cubes, 'frac', stash_lookup_func=stash)
        if not frac:
            print("  ⚠ fracPFTs (frac, m01s19i013): NOT FOUND, trying stash code 3317")
            frac = try_extract(cubes, 3317)
            if not frac:
                print("  ❌ fracPFTs: STILL NOT FOUND")
            else:
                print("  ✓ fracPFTs: Found (via stash code 3317)")
        else:
            print("  ✓ fracPFTs (frac): Found")

        gpp = try_extract(cubes, 'gpp', stash_lookup_func=stash)
        if not gpp:
            print("  ❌ GPP (gpp, m01s03i261): NOT FOUND")
        else:
            print("  ✓ GPP (gpp): Found")

        npp = try_extract(cubes, 'npp', stash_lookup_func=stash)
        if not npp:
            print("  ❌ NPP (npp, m01s03i262): NOT FOUND")
        else:
            print("  ✓ NPP (npp): Found")

        fgco2 = try_extract(cubes, 'fgco2', stash_lookup_func=stash)
        if not fgco2:
            print("  ❌ fgco2 (fgco2, m02s30i249): NOT FOUND")
        else:
            print("  ✓ fgco2: Found")

        temp = try_extract(cubes, 'tas', stash_lookup_func=stash)
        if not temp:
            print("  ❌ temp (tas, m01s03i236): NOT FOUND")
        else:
            print("  ✓ temp (tas): Found")

        precip = try_extract(cubes, 'pr', stash_lookup_func=stash)
        if not precip:
            print("  ❌ precip (pr, m01s05i216): NOT FOUND")
        else:
            print("  ✓ precip (pr): Found")

        dict_frac[expt] = frac
        dict_temp[expt] = temp
        dict_precip[expt] = precip

        cube_list = [sr, sc, vc, frac, gpp, npp, fgco2, temp, precip]

        # Summary of extraction status
        missing_vars = []
        found_vars = []
        for cubeset, varname in zip(cube_list, var_list):
            if not cubeset:
                missing_vars.append(varname)
            else:
                found_vars.append(varname)

        print(f"\n{'='*60}")
        print(f"Extraction Summary for {expt}")
        print(f"{'='*60}")
        print(f"Variables successfully extracted: {len(found_vars)}/{len(var_list)}")
        if found_vars:
            print(f"  Found: {', '.join(found_vars)}")
        if missing_vars:
            print(f"  ⚠ Missing: {', '.join(missing_vars)}")
            print(f"\n  These variables will NOT appear in plots!")
        print(f"{'='*60}\n")

        for region in target_regions:
            dict_annual_means[expt][region] = {}
            for i, (cubeset, varname, mapping) in enumerate(zip(cube_list, var_list, var_mapping)):
                if not cubeset:
                    continue  # Already warned above
                if varname == 'fgco2' and region != 'global':
                    continue  # Skip fgco2 for non-global regions

                cube = cubeset[0]
                # Handle regular variables
                if cube is not None and varname != 'fracPFTs':
                    output = compute_regional_annual_mean(cube, mapping, region)
                    output['units'] = {
                        'temp': 'K',
                        'precip': 'mm/day'
                    }.get(varname, 'PgC/year')
                    dict_annual_means[expt][region][varname] = output
                # Handle fracPFTs separately
                else:
                    frac_data = {}
                    for j in range(1, 10):
                        try:
                            frac_pft = cube.extract(Constraint(coord_values={'generic': j}))
                            output = compute_regional_annual_mean(frac_pft, mapping, region)
                            frac_data[f'PFT {j}'] = output
                        except:
                            continue
                    dict_annual_means[expt][region][varname] = frac_data

            # NEP
            if 'NPP' in dict_annual_means[expt][region] and 'soilResp' in dict_annual_means[expt][region]:
                nep_years = dict_annual_means[expt][region]['NPP']['years'].copy()
                nep_data = dict_annual_means[expt][region]['NPP']['data'] - dict_annual_means[expt][region]['soilResp']['data']
                dict_annual_means[expt][region]['NEP'] = {
                    'years': nep_years,
                    'data': nep_data,
                    'name': 'Net Ecosystem Production',
                    'units': dict_annual_means[expt][region]['NPP']['units'],
                    'region': region
                }

            # Land Carbon
            if all(k in dict_annual_means[expt][region] for k in ['soilCarbon', 'VegCarb', 'NEP']):
                lc_years = dict_annual_means[expt][region]['NEP']['years'].copy()
                lc_data = dict_annual_means[expt][region]['soilCarbon']['data'] + \
                          dict_annual_means[expt][region]['VegCarb']['data'] + \
                          dict_annual_means[expt][region]['NEP']['data']
                dict_annual_means[expt][region]['Land Carbon'] = {
                    'years': lc_years,
                    'data': lc_data,
                    'name': 'Total Land Carbon',
                    'units': dict_annual_means[expt][region]['NPP']['units'],
                    'region': region
                }

            # Trees Total
            if 'fracPFTs' in dict_annual_means[expt][region] and \
               all(p in dict_annual_means[expt][region]['fracPFTs'] for p in ['PFT 1', 'PFT 2']):
                tree_years = dict_annual_means[expt][region]['fracPFTs']['PFT 1']['years'].copy()
                tree_data = dict_annual_means[expt][region]['fracPFTs']['PFT 1']['data'] + \
                            dict_annual_means[expt][region]['fracPFTs']['PFT 2']['data']
                dict_annual_means[expt][region]['Trees Total'] = {
                    'years': tree_years,
                    'data': tree_data,
                    'name': 'Total Trees Fraction',
                    'units': 'fraction',
                    'region': region
                }

    return dict_annual_means
