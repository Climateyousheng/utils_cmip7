"""
High-level extraction from pre-processed annual mean NetCDF files.

Main entry point for extracting carbon cycle variables from annual mean files
generated by CDO or similar tools.
"""

import os
import glob
import warnings
import numpy as np

# Configure Iris and suppress warnings before importing
try:
    import iris
    iris.FUTURE.date_microseconds = True
except AttributeError:
    import iris

# Suppress Iris warnings
warnings.filterwarnings('ignore', message='.*date precision.*', category=FutureWarning)
warnings.filterwarnings('ignore', message='.*DEFAULT_SPHERICAL_EARTH_RADIUS.*')

from iris import Constraint

from ..io import stash, try_extract
from ..processing.regional import load_reccap_mask, compute_regional_annual_mean, _get_land_mask
from iris.analysis.cartography import area_weights
from ..config import (
    DEFAULT_VAR_LIST,
    resolve_variable_name,
    get_variable_config,
    get_conversion_key,
)

__all__ = [
    'extract_annual_means',
    'compute_latlon_box_mean',
]


def compute_latlon_box_mean(cube, lon_bounds, lat_bounds, land_only=False):
    """
    Compute area-weighted mean for a lat/lon bounding box.

    Parameters
    ----------
    cube : iris.cube.Cube
        Input cube with lat/lon dimensions
    lon_bounds : tuple of float
        (lon_min, lon_max) in degrees East (0-360)
    lat_bounds : tuple of float
        (lat_min, lat_max) in degrees North (-90 to 90)
    land_only : bool, optional
        If True, restrict the spatial average to land grid cells
        (derived from RECCAP2 mask). Default: False

    Returns
    -------
    iris.cube.Cube
        Spatially collapsed cube (area-weighted mean over box)
    """
    # Extract lat/lon box
    lon_constraint = Constraint(
        longitude=lambda cell: lon_bounds[0] <= cell <= lon_bounds[1]
    )
    lat_constraint = Constraint(
        latitude=lambda cell: lat_bounds[0] <= cell <= lat_bounds[1]
    )

    regional_cube = cube.extract(lon_constraint & lat_constraint)

    if regional_cube is None:
        raise ValueError(f"No data found in box lon={lon_bounds}, lat={lat_bounds}")

    # Ensure bounds exist for area weighting
    if not regional_cube.coord('latitude').has_bounds():
        regional_cube.coord('latitude').guess_bounds()
    if not regional_cube.coord('longitude').has_bounds():
        regional_cube.coord('longitude').guess_bounds()

    # Compute area weights
    weights = area_weights(regional_cube)

    # Apply land mask to weights if requested
    if land_only:
        full_land_mask = _get_land_mask()
        # Extract the same lat/lon sub-region from the land mask
        lat_idx = np.where(
            (cube.coord('latitude').points >= lat_bounds[0]) &
            (cube.coord('latitude').points <= lat_bounds[1])
        )[0]
        lon_idx = np.where(
            (cube.coord('longitude').points >= lon_bounds[0]) &
            (cube.coord('longitude').points <= lon_bounds[1])
        )[0]
        land_sub = full_land_mask[np.ix_(lat_idx, lon_idx)]
        # Broadcast to match weights shape (handles time dimension)
        if weights.ndim == 3:
            land_sub = land_sub[None, :, :]
        elif weights.ndim == 4:
            land_sub = land_sub[None, None, :, :]
        weights = weights * land_sub

    # Collapse spatial dimensions
    regional_cube.data = np.ma.masked_invalid(regional_cube.data)
    mean_cube = regional_cube.collapsed(['latitude', 'longitude'],
                                        iris.analysis.MEAN,
                                        weights=weights)

    return mean_cube


def extract_annual_means(expts_list, var_list=None, regions=None, base_dir='~/annual_mean'):
    """
    Extract annual means from pre-processed NetCDF files.

    Main workhorse function for extracting carbon cycle variables from
    pre-processed annual mean files.

    Parameters
    ----------
    expts_list : list of str
        List of experiment names (e.g., ['xqhuc', 'xqhsh'])
    var_list : list of str, optional
        Variable names to extract (CMIP-style canonical names).
        Default: ['Rh', 'CSoil', 'CVeg', 'frac', 'GPP', 'NPP', 'fgco2', 'tas', 'pr', 'co2']
    regions : list of str, optional
        Region names to process. Default: all RECCAP2 regions + 'Africa' + 'global'
    base_dir : str, optional
        Base directory containing experiment subdirectories with annual mean files.
        Default: '~/annual_mean'

        Each experiment should have a subdirectory: {base_dir}/{expt}/

    Returns
    -------
    dict
        Nested dictionary with structure:
        {expt: {region: {var: {'years': array, 'data': array, 'units': str,
                                'name': str, 'region': str}}}}

    Examples
    --------
    >>> # Extract for single experiment, all regions (using canonical names)
    >>> ds = extract_annual_means(['xqhuc'])
    >>> ds['xqhuc']['global']['GPP']['data']  # Global GPP time series
    >>> ds['xqhuc']['global']['Rh']['data']   # Heterotrophic respiration

    >>> # Extract for multiple experiments, specific regions
    >>> ds = extract_annual_means(['xqhuc', 'xqhsh'],
    ...                          regions=['global', 'Europe', 'Africa'])
    >>> ds['xqhuc']['Europe']['NPP']['data']  # Europe NPP for xqhuc

    >>> # With custom base directory
    >>> ds = extract_annual_means(['xqhuc'], base_dir='~/data/annual_mean')

    Notes
    -----
    Input files expected in: {base_dir}/{expt}/
    - {expt}_pt_annual_mean.nc (TRIFFID: GPP, NPP, soil resp, carbon, PFTs)
    - {expt}_pd_annual_mean.nc (atmosphere: temp, precip)
    - {expt}_pf_annual_mean.nc (ocean: fgco2)

    Derived variables computed automatically:
    - NEP = NPP - Rh
    - Land Carbon = CSoil + CVeg + NEP
    - Trees Total = PFT1 + PFT2

    Detailed diagnostic output printed to stdout showing:
    - Files found
    - Variables successfully extracted (✓) or missing (❌)
    - Summary of extraction status

    See Also
    --------
    config.CANONICAL_VARIABLES : Variable registry with all metadata
    config.resolve_variable_name : Resolve aliases to canonical names
    """
    # Use default variable list if not provided
    if var_list is None:
        var_list = DEFAULT_VAR_LIST

    # Resolve variable names to canonical names
    resolved_vars = []
    for var in var_list:
        try:
            canonical = resolve_variable_name(var)
            resolved_vars.append(canonical)
        except ValueError as e:
            warnings.warn(f"Skipping unknown variable '{var}': {e}", UserWarning, stacklevel=2)

    var_list = resolved_vars

    dict_annual_means = {}
    dict_frac = {}
    dict_temp = {}
    dict_precip = {}

    _, regions_dict = load_reccap_mask()
    all_regions = list(regions_dict.values()) + ['Africa', 'global']
    target_regions = regions if regions is not None else all_regions

    for expt in expts_list:
        expt_dir = os.path.join(base_dir, expt)
        dict_annual_means[expt] = {}
        expt_dir = os.path.expanduser(expt_dir)
        os.makedirs(expt_dir, exist_ok=True)

        filenames = glob.glob(os.path.join(expt_dir, "**/*.nc"), recursive=True)

        # Report files found
        print(f"\n{'='*60}")
        print(f"Extracting data for experiment: {expt}")
        print(f"{'='*60}")
        print(f"Looking in: {expt_dir}")
        print(f"NetCDF files found: {len(filenames)}")
        if filenames:
            for f in filenames:
                print(f"  - {os.path.basename(f)}")
        else:
            print(f"  ⚠ WARNING: No NetCDF files found!")
            print(f"  Expected files like: {expt}_pt_annual_mean.nc, {expt}_pd_annual_mean.nc, {expt}_pf_annual_mean.nc")

        cubes = iris.load(filenames)
        print(f"\nTotal cubes loaded: {len(cubes)}")

        # Extract variables using canonical registry
        print(f"\nExtracting variables...")

        # Build cube map using canonical names
        cube_map = {}

        for var_name in var_list:
            try:
                var_config = get_variable_config(var_name)
                stash_name = var_config['stash_name']
                stash_code = var_config['stash_code']
                stash_fallback = var_config.get('stash_fallback')
                var_name_fallback = var_config.get('var_name_fallback')

                # Try primary extraction
                extracted = try_extract(cubes, stash_name, stash_lookup_func=stash)
                found_via = stash_name if extracted else None

                if not extracted and stash_fallback:
                    # Try STASH fallback (e.g., frac → fracb)
                    print(f"  ⚠ {var_name} ({stash_name}, {stash_code}): NOT FOUND, trying fallback {stash_fallback}")
                    extracted = try_extract(cubes, stash_fallback)
                    if extracted:
                        found_via = f"STASH fallback {stash_fallback}"

                if not extracted and var_name_fallback:
                    # Try matching by NetCDF variable name (e.g., fracpfts)
                    from iris import Constraint
                    extracted = cubes.extract(
                        Constraint(cube_func=lambda c, _vn=var_name_fallback: c.var_name == _vn)
                    )
                    if extracted:
                        found_via = f"var_name '{var_name_fallback}'"

                if extracted:
                    print(f"  ✓ {var_name}: Found (via {found_via})")
                else:
                    print(f"  ❌ {var_name} ({stash_name}, {stash_code}): NOT FOUND")

                cube_map[var_name] = extracted

            except Exception as e:
                # Don't let one variable failure stop the entire extraction
                print(f"  ❌ {var_name}: ERROR during extraction: {e}")
                import traceback
                traceback.print_exc()
                cube_map[var_name] = None

        # Store specific variables for backward compatibility
        dict_frac[expt] = cube_map.get('frac')
        dict_temp[expt] = cube_map.get('tas')
        dict_precip[expt] = cube_map.get('pr')

        # Summary of extraction status
        missing_vars = []
        found_vars = []
        for varname in var_list:
            cubeset = cube_map.get(varname)
            if not cubeset:
                missing_vars.append(varname)
            else:
                found_vars.append(varname)

        print(f"\n{'='*60}")
        print(f"Extraction Summary for {expt}")
        print(f"{'='*60}")
        print(f"Variables successfully extracted: {len(found_vars)}/{len(var_list)}")
        if found_vars:
            print(f"  Found: {', '.join(found_vars)}")
        if missing_vars:
            print(f"  ⚠ Missing: {', '.join(missing_vars)}")
            print(f"\n  These variables will NOT appear in plots!")
        print(f"{'='*60}\n")

        for region in target_regions:
            dict_annual_means[expt][region] = {}

            # Process each variable using canonical names and automatic conversion keys
            for varname in var_list:
                try:
                    cubeset = cube_map.get(varname)
                    if not cubeset:
                        continue  # Already warned above
                    if varname == 'fgco2' and region != 'global':
                        continue  # Skip fgco2 for non-global regions

                    cube = cubeset[0]
                    var_config = get_variable_config(varname)
                    conversion_key = get_conversion_key(varname)

                    # Handle regular variables
                    if cube is not None and varname != 'frac':
                        output = compute_regional_annual_mean(cube, conversion_key, region)
                        output['units'] = var_config['units']
                        dict_annual_means[expt][region][varname] = output
                    # Handle frac (PFTs) separately
                    elif cube is not None and varname == 'frac':
                        frac_data = {}

                        # Load IGBP obs for spatial RMSE (only for global region)
                        igbp_ds = None
                        if region == 'global':
                            try:
                                from ..validation.veg_fractions import (
                                    load_igbp_spatial, compute_spatial_rmse,
                                    compute_spatial_rmse_weighted, PFT_MAPPING
                                )
                                igbp_ds = load_igbp_spatial()
                            except (ImportError, Exception):
                                pass

                        for j in range(1, 10):
                            try:
                                frac_pft = cube.extract(Constraint(coord_values={'generic': j}))
                                if frac_pft:
                                    output = compute_regional_annual_mean(frac_pft, conversion_key, region, land_only=True)

                                    # Compute spatial RMSE against IGBP obs (global only, veg PFTs only)
                                    if region == 'global' and igbp_ds is not None:
                                        pft_name = PFT_MAPPING.get(j)
                                        spatial_var = f'{pft_name}_2D' if pft_name else None
                                        if (spatial_var and spatial_var in igbp_ds
                                                and pft_name != 'bare_soil'):
                                            try:
                                                # Time-mean of model field (preserve lat/lon)
                                                model_field = frac_pft.collapsed('time', iris.analysis.MEAN).data
                                                obs_field = igbp_ds[spatial_var].squeeze().values
                                                lats = frac_pft.coord('latitude').points
                                                output['rmse'] = compute_spatial_rmse(model_field, obs_field)
                                                output['rmse_w'] = compute_spatial_rmse_weighted(
                                                    model_field, obs_field, lats
                                                )
                                            except Exception:
                                                pass

                                    frac_data[f'PFT {j}'] = output
                            except Exception as e:
                                # Skip PFTs that fail extraction
                                continue

                        # Close IGBP dataset if opened
                        if igbp_ds is not None:
                            igbp_ds.close()

                        # Compute custom regional tree metrics (global region only)
                        if region == 'global' and 'PFT 1' in frac_data and 'PFT 2' in frac_data:
                            try:
                                # Amazon trees: 290-320°E, 15°S-5°N (BL + NL)
                                bl_cube = cube.extract(Constraint(coord_values={'generic': 1}))  # BL
                                nl_cube = cube.extract(Constraint(coord_values={'generic': 2}))  # NL

                                if bl_cube and nl_cube:
                                    # Amazon
                                    bl_amz = compute_latlon_box_mean(bl_cube, (290, 320), (-15, 5), land_only=True)
                                    nl_amz = compute_latlon_box_mean(nl_cube, (290, 320), (-15, 5), land_only=True)
                                    amz_trees = bl_amz + nl_amz
                                    amz_output = {
                                        'years': frac_data['PFT 1']['years'],
                                        'data': amz_trees.data,
                                        'units': 'fraction',
                                        'name': 'AMZTrees',
                                        'region': 'Amazon (290-320E, 15S-5N)'
                                    }
                                    frac_data['AMZTrees'] = amz_output

                                    # Subtropical trees: 0-360°E, 30°S-30°N (BL + NL)
                                    bl_trop = compute_latlon_box_mean(bl_cube, (0, 360), (-30, 30), land_only=True)
                                    nl_trop = compute_latlon_box_mean(nl_cube, (0, 360), (-30, 30), land_only=True)
                                    trop_trees = bl_trop + nl_trop
                                    trop_output = {
                                        'years': frac_data['PFT 1']['years'],
                                        'data': trop_trees.data,
                                        'units': 'fraction',
                                        'name': 'Tr30SN',
                                        'region': 'Subtropical (30S-30N)'
                                    }
                                    frac_data['Tr30SN'] = trop_output

                                    # NH trees: 0-360°E, 30°N-90°N (BL + NL)
                                    # Note: Using 30-60N as per code snippet (adjust if needed)
                                    bl_nh = compute_latlon_box_mean(bl_cube, (0, 360), (30, 60), land_only=True)
                                    nl_nh = compute_latlon_box_mean(nl_cube, (0, 360), (30, 60), land_only=True)
                                    nh_trees = bl_nh + nl_nh
                                    nh_output = {
                                        'years': frac_data['PFT 1']['years'],
                                        'data': nh_trees.data,
                                        'units': 'fraction',
                                        'name': 'Tr30-90N',
                                        'region': 'NH (30N-60N)'
                                    }
                                    frac_data['Tr30-90N'] = nh_output

                            except Exception as e:
                                print(f"  ⚠ Warning: Failed to compute regional tree metrics: {e}")

                        # Only add frac data if at least one PFT was successfully extracted
                        if frac_data:
                            dict_annual_means[expt][region][varname] = frac_data

                except Exception as e:
                    # Don't let regional processing errors stop the entire extraction
                    print(f"  ⚠ Warning: Failed to process {varname} for region {region}: {e}")
                    continue

            # NEP (derived variable: NPP - Rh)
            if 'NPP' in dict_annual_means[expt][region] and 'Rh' in dict_annual_means[expt][region]:
                nep_years = dict_annual_means[expt][region]['NPP']['years'].copy()
                nep_data = dict_annual_means[expt][region]['NPP']['data'] - dict_annual_means[expt][region]['Rh']['data']
                dict_annual_means[expt][region]['NEP'] = {
                    'years': nep_years,
                    'data': nep_data,
                    'name': 'Net Ecosystem Production',
                    'units': dict_annual_means[expt][region]['NPP']['units'],
                    'region': region
                }

            # Land Carbon (derived variable: CSoil + CVeg + NEP)
            if all(k in dict_annual_means[expt][region] for k in ['CSoil', 'CVeg', 'NEP']):
                lc_years = dict_annual_means[expt][region]['NEP']['years'].copy()
                lc_data = dict_annual_means[expt][region]['CSoil']['data'] + \
                          dict_annual_means[expt][region]['CVeg']['data'] + \
                          dict_annual_means[expt][region]['NEP']['data']
                dict_annual_means[expt][region]['Land Carbon'] = {
                    'years': lc_years,
                    'data': lc_data,
                    'name': 'Total Land Carbon',
                    'units': dict_annual_means[expt][region]['NPP']['units'],
                    'region': region
                }

            # Trees Total (PFT1 + PFT2)
            if 'frac' in dict_annual_means[expt][region] and \
               all(p in dict_annual_means[expt][region]['frac'] for p in ['PFT 1', 'PFT 2']):
                tree_years = dict_annual_means[expt][region]['frac']['PFT 1']['years'].copy()
                tree_data = dict_annual_means[expt][region]['frac']['PFT 1']['data'] + \
                            dict_annual_means[expt][region]['frac']['PFT 2']['data']
                dict_annual_means[expt][region]['Trees Total'] = {
                    'years': tree_years,
                    'data': tree_data,
                    'name': 'Total Trees Fraction',
                    'units': 'fraction',
                    'region': region
                }

    return dict_annual_means
